{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "significant-conducting",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Before getting to our prediction algorithm, our data must go through different processes, in different subsets.\n",
    "The order of such processes is often misunderstood.\n",
    "For this reason, we are going to start from a picture summing up the whole process, and go through it step by step.\n",
    "\n",
    "![data_pipeline](images/flowchart.png)\n",
    "\n",
    "1. **Data Cleaning**: Here is where we handle *missing* values from our dataset. In our case we also perform an *Ordinal Encoding*, to ease later steps.\n",
    "2. **Data Split**: At this point, we take away a small portion of data and put it aside. This small portion will simulate newly gathered data, and it will be essential to test the generalization power of our final model.\n",
    "3. **Training Path**:\n",
    "    1. **Oversampling**: We use SMOTE to oversample **only training data**. Since the real world is unbalanced, if we were to balance also the test set, we would cheat, and offer a distorted vision of what our model would expect.\n",
    "    2. **Scaling**: Some ML do not have any problem with our data having different scales (i.e. Trees), but some of them do (i.e. SVM). In order to have a unique pipeline that works with every kind of algorithm, we will always apply scaling.\n",
    "    2. **One-Hot-Encoding**: Ordinal encoding can put our data on different levels that are not really there (i.e. when mapping colors with numbers, there is no reason of assigning 1 to 'black' or 'white'). For this reason, we apply one-hot-encoding. This will avoid the aforementioned problem, but has the drawback of increasing the dimensionality of our data (creating a sparse encoding matrix).\n",
    "\n",
    "The horizontal arrows mean that we apply the same process, but we only transform data using statistics computed on the training set. i.e. when performing a normalization (scaling), we scale test data using mean and variance computed on training data.\n",
    "\n",
    "The missing part of the chart deals with the actual classification task, which we will see in a while.\n",
    "Now, let's prepare our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-character",
   "metadata": {},
   "source": [
    "## Training-Test Dataset Split\n",
    "\n",
    "To make the code more compact and readable, we are going to use sklearn's pipeline object to create a reusable pipeline of actions.\n",
    "\n",
    "The first step is to put aside a small portion of the dataset, and call it our *test data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thorough-imaging",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (9864, 18)\t\ttest data shape: (2466, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('./dataset/online_shoppers_intention.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "x_train, y_train = df_train.drop(columns='Revenue'), df_train['Revenue']\n",
    "print(f'training data shape: {df_train.shape}\\t\\ttest data shape: {df_test.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-metabolism",
   "metadata": {},
   "source": [
    "## Column Transformer\n",
    "For all those actions that require statistics computed column-wise, we use the *ColumnTransformer* object, in which we can insert all those procedures like *Encoding* and *Scaling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blond-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "textual_columns = ['Month', 'VisitorType', 'Weekend']\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "numerical_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "        ('OrdinalEncoder', OrdinalEncoder(), textual_columns),\n",
    "#         ('MinMaxScaler', MinMaxScaler(), numerical_columns),\n",
    "#         ('OneHotEncoder', OneHotEncoder(), categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-arena",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "We can then inset the column transformer inside a pipeline alongisde the *oversampling* technique that we desire, and the classification algorithm (here we use a *Random Forest* as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "parental-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "categorical_features = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "categorical_indices = [c in categorical_features for c in df_train.columns]\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('ColumnTransformer', column_transformer),\n",
    "        ('SMOTENC', SMOTENC(categorical_features=categorical_indices)),\n",
    "        ('Classifier', RandomForestClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-general",
   "metadata": {},
   "source": [
    "## GridSearch & CrossValidation\n",
    "\n",
    "*GridSearch* is one of many approaches to *hyperparameter optimization* or *model selection*. It is an exaustive search of a predefined subset of hyperparameters (values for continuos parameters are implicitly discretized). The algorithm is then trained with each n-uple in the cartesian product of the sets of each parameter, and is evaluated on a held-out validation set.\n",
    "\n",
    "Since we are also doing *CrossValidation*, each hyperparameter configuration is evaluated on each of the k folds in which we split our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunrise-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we define the subset of parameters to use in the gridsearch model selection technique\n",
    "param_grid = [\n",
    "    {\n",
    "        'Classifier__random_state': [42],\n",
    "        'Classifier__n_estimators': [10, 50, 100]\n",
    "    }\n",
    "]\n",
    "\n",
    "# And here we put together every piece of the pipeline to create a reusable structure in which we can plug in different\n",
    "# Models and transformers without going through the effort of writing again a big bunch of code\n",
    "# TODO: uncomment\n",
    "# linear_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=6).fit(x_train, y_train)\n",
    "# linear_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-scanner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "source_map": [
   14,
   36,
   44,
   56,
   61,
   76,
   81,
   95,
   103,
   121
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}