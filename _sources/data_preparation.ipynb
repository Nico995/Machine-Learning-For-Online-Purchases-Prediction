{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-decision",
   "metadata": {},
   "source": [
    "(chapters:pipelines)=\n",
    "# Pipelines\n",
    "\n",
    "Before getting to our prediction algorithm, our data must go through different processes, in different subsets.\n",
    "The order of such processes is often misunderstood.\n",
    "For this reason, we are going to start from a picture summing up the whole process, and go through it step by step.\n",
    "\n",
    "![data_pipeline](images/flowchart2.png)\n",
    "\n",
    "1. **Data**: It is our starting data as we read it from the filesystem.\n",
    "2. **Training/Test Split**: We take away a portion of our data, that we will use to test our model at the end of the process. This portion of data must reflect the underlying distribution as good as possible. (Sampling must be stratified to retain proportions).\n",
    "3. **Scaling**: We change the range of our data. If this is a *normalization*, we compute the statistics over the training set, and use them to normalize the test set.\n",
    "4. **OHE**: We encode our catecorical data into a presence matrix. Again, we build the dictionary of possible values from the training set, and apply it on the test set. Values that are only seen in the test set need to be handled (i.e. dropped, Na)\n",
    "5. **SMOTE**: We perform oversampling of our data. **We only perform oversampling on the training dataset**. We need to keep the test set unchanged from the distribution point of view.\n",
    "6. **Cross Validation (Model Selection)**: We perform model selection jointly with cross-validation. We evaluate different configuration of the same model on k disjoint subsets of our training sample. We take the configuration with the lowest average error (highest average metric) on the k folds.\n",
    "7. **Training**: Now that we discovered our \"best\" model, we can train it from scratch using the whole training set provided.\n",
    "8. **Test**: We assess the generalization power of our model by evaluating it on the test set, which was never shown before to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-musical",
   "metadata": {},
   "source": [
    "## Training-Test Dataset Split\n",
    "\n",
    "To make the code more compact and readable, we are going to use sklearn's pipeline object to create a reusable pipeline of actions.\n",
    "\n",
    "The first step is to put aside a small portion of the dataset, and call it our *test data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "representative-singapore",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (9864, 18)\t\ttest data shape: (2466, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('./dataset/online_shoppers_intention.csv')\n",
    "# Stratified by default\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "x_train, y_train = df_train.drop(columns='Revenue'), df_train['Revenue']\n",
    "print(f'training data shape: {df_train.shape}\\t\\ttest data shape: {df_test.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-rates",
   "metadata": {},
   "source": [
    "By default, the *train_test_split* function makes use of the *y* argument to perform stratified sampling. This means that we are sampling out a test set from our starting data, which keeps the class proportions intact. This is of utmost importance since it is the necessary condition to have a valid test score of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-riverside",
   "metadata": {},
   "source": [
    "## Column Transformer\n",
    "For all those actions that require statistics computed column-wise, we use the *ColumnTransformer* object, in which we can insert those procedures like *Encoding* and *Scaling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sound-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "textual_columns = ['Month', 'VisitorType', 'Weekend']\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "numerical_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "        ('OrdinalEncoder', OrdinalEncoder(), textual_columns),\n",
    "#         ('MinMaxScaler', MinMaxScaler(), numerical_columns),\n",
    "#         ('OneHotEncoder', OneHotEncoder(), categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-choice",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "We can then inset the column transformer inside a pipeline alongisde the *oversampling* technique that we desire, and the classification algorithm (here we use a *Random Forest* as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "categorical_features = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "categorical_indices = [c in categorical_features for c in df_train.columns]\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('ColumnTransformer', column_transformer),\n",
    "        ('SMOTENC', SMOTENC(categorical_features=categorical_indices)),\n",
    "        ('Classifier', RandomForestClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-violence",
   "metadata": {},
   "source": [
    "## GridSearch & CrossValidation\n",
    "\n",
    "*GridSearch* is one of many approaches to *hyperparameter optimization* or *model selection*. It is an exaustive search of a predefined subset of hyperparameters (values for continuos parameters are implicitly discretized). The algorithm is then trained with each n-uple in the cartesian product of the sets of each parameter, and is evaluated on a held-out validation set.\n",
    "\n",
    "Since we are also doing *CrossValidation*, each hyperparameter configuration is evaluated on each of the k folds in which we split our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unable-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we define the subset of parameters to use in the gridsearch model selection technique\n",
    "param_grid = [\n",
    "    {\n",
    "        'Classifier__random_state': [42],\n",
    "        'Classifier__n_estimators': [10, 50, 100]\n",
    "    }\n",
    "]\n",
    "\n",
    "# And here we put together every piece of the pipeline to create a reusable structure in which we can plug in different\n",
    "# Models and transformers without going through the effort of writing again a big bunch of code\n",
    "# This is commented for time-resource reasons\n",
    "# linear_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=6).fit(x_train, y_train)\n",
    "# linear_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-cream",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "To know more about Grid Search & Cross Validation and what's really behind it, have a look at the Appendix, or click [here](appendix:gridsearchcv)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "source_map": [
   14,
   34,
   42,
   55,
   59,
   64,
   79,
   84,
   98,
   106,
   122
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}