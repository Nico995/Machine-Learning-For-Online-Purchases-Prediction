{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affected-blond",
   "metadata": {},
   "source": [
    "(chapters:model_exploration)=\n",
    "# Model Exploration\n",
    "\n",
    "This section is **not** called model selection because our final goal is not to find the model with the best average of the true error estimation. We instead aim to showcase the common Data Science pipeline and try multiple models, showing at the same time the programming side and the mathematical side of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-coral",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machines\n",
    "\n",
    "This algorithm tries to find a hyperplane that divides the saples living in the feature space, maximizing the minimum distance between the hyperplane itself and the closest point in both resulting halfspaces. \n",
    "\n",
    "### 1.1 Theory\n",
    "\n",
    "#### 1.1.1 Margin and Hard-SVM\n",
    "\n",
    "Let $S = \\left(\\mathbf{x}_1, \\mathcal{y}_1\\right)\\dots\\left(\\mathbf{x}_m, \\mathcal{y}_m\\right)$ be the training set of size m, where each $\\mathbf{x}_i\\in\\mathbb{R}^d$ and $\\mathcal{y}_i\\in\\{\\pm1\\}$. We say that the training set is linearelt separable, if there exists a halfspace, $\\left(\\mathbf{w}, \\mathcal{b}\\right)$ such that $y_{i}=\\operatorname{sign}\\left(\\left\\langle\\mathbf{w}, \\mathbf{x}_{i}\\right\\rangle+b\\right)$ for all $i$. We can write this condition as:\n",
    "\n",
    "$$\\forall i \\in \\left[m\\right],\\ y_i\\left(\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right)>0$$\n",
    "\n",
    "All halfspaces $\\left(\\mathbf{w}, \\mathcal{b}\\right)$ that satisfiy the condition above are $\\operatorname{ERM}$ hypotheses (and their 0-1 error is zero). For any **separable** training set, there are many $\\operatorname{ERM}$ halfspaces, which one should we pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-chair",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "xp = [-2, -1, 1, 2]\n",
    "yp = [-1, -2, 2, 1]\n",
    "c = [0, 1, 0, 1]\n",
    "\n",
    "m1, q1 = 1, 0\n",
    "m2, q2 = 1.3, 0\n",
    "x = np.linspace(-3, 3, 100)\n",
    "y1 = x*m1 + q1\n",
    "y2 = x*m2 + q2\n",
    "ax = sns.lineplot(x=x, y=y1, palette=\"tab10\", color='red')\n",
    "sns.lineplot(x=x, y=y2, palette=\"tab10\", color='green')\n",
    "sns.scatterplot(x=xp, y=yp, style=c, ax=ax, legend=False, s=70)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-antibody",
   "metadata": {},
   "source": [
    "Intuitively we might choose the red hyperplane to split our data, in order to formalize this intuition we introduce the concept of margin.\n",
    "\n",
    "```{admonition} Margin\n",
    ":class: important\n",
    "The margin of a hyperplane with respect to a training set is the minimal distance between a point in the training set and the hyperplane\n",
    "```\n",
    "\n",
    "Note that if a hyperplane has a large margin, even if we sligthly perturn each dataset instance, it will still separate the data *correctly*.\n",
    "\n",
    "As we will see later, the larger is the margin that a halfspace has over the training sample, the smaller is the true error of the halfspace. For this reason the *Hard-SVM* rule is the rule that returns an $ERM$ hyperplane that separates the training set with the largest possible margin.\n",
    "\n",
    "* Claim: The distance between a point $\\mathbf{x}$ and the hyperplane defined by $\\left(\\mathbf{w},b\\right)$ where $\\left\\lVert\\mathbb{w}\\right\\rVert=1$ is $\\left\\lvert\\left\\langle\\mathbf{w, x}\\right\\rangle+b\\right\\rvert$\n",
    "\n",
    "On this basis, the point $\\mathbf{x_i}\\in S$ closest to the hyperplane $L$ is\n",
    "\n",
    "$$d\\left(\\mathbf{x},L\\right)=\\underset{i\\in\\left[m\\right]}{\\operatorname{min}}\\left\\lvert\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right\\rvert$$\n",
    "\n",
    "Hence, the Hard-SVM rule is \n",
    "\n",
    "```{admonition} Hard-SVM rule\n",
    ":class: important\n",
    "$$\\underset{\\left(\\mathbf{w}, b\\right):\\left\\lVert\\mathbf{w}=1\\right\\rVert}{\\operatorname{argmax}}\\underset{i\\in\\left[m\\right]}{\\operatorname{min}}\\left\\lvert\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right\\rvert\\ \\ s.t.\\ \\ \\forall i, \\ \\mathcal{y_i}\\left(\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right)>0\\tag{1}$$\n",
    "\n",
    "Equivalently \n",
    "\n",
    "$$\\underset{\\left(\\mathbf{w}, b\\right):\\left\\lVert\\mathbf{w}=1\\right\\rVert}{\\operatorname{argmax}}\\underset{i\\in\\left[m\\right]}{\\operatorname{min}}\\mathcal{y_i}\\left(\\left\\langle\\mathbf{x, x_i}\\right\\rangle+b\\right)\\tag{2}$$\n",
    "\n",
    "Equivalently\n",
    "\n",
    "$$\\underset{\\left(\\mathbf{w}, b\\right)}{\\operatorname{argmin}}\\left\\lVert\\mathbf{w}\\right\\rVert^2\\ \\operatorname{s.t.}\\ \\forall i,\\ \\mathcal{y_i}\\left(\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right)>1\\tag{3}$$\n",
    "```\n",
    "\n",
    "Intuitively, we are going from maximizing the numerator of the distance formula (maximizing the minimal distance) to minimizing the norm of $w$.\n",
    "The last equation can be solved via quadratic programming.\n",
    "\n",
    "We now have to define a new concept of separability:\n",
    "\n",
    "```{admonition} $\\left(\\gamma,\\rho\\right)$-margin\n",
    ":class: important\n",
    "We say that $\\mathcal{D}$ is separable with a $\\left(\\gamma,\\rho\\right)$-margin if exists $\\left(\\mathbf{w^*}, b^*\\right)\\ \\operatorname{s.t.}\\ \\left\\lVert\\mathbf{w^*}\\right\\rVert=1$ and\n",
    "\n",
    "$$\\mathcal{D}\\left(\\{\\left(x, y\\right): \\left\\lVert x\\right\\rVert\\leq\\rho \\wedge \\mathcal{y}\\left(\\left\\langle\\mathbf{w^*, x}\\right\\rangle+b^*\\right)>1 \\}\\right)=1$$\n",
    "\n",
    "This means that when we say that $\\mathcal{D}$ is separable with a $\\left(\\gamma,\\rho\\right)$-margin, if there is a ball of radius $\\rho$ inside which the hyperplane can **always** separate the points (finite set of points can violate the separability)\n",
    "```\n",
    "\n",
    "We can now state the theorem that gives us the sample complexity for Hard-SVM (without proving it)\n",
    "\n",
    "```{admonition} Hard-SVM Sample complexity\n",
    ":class: important\n",
    "if $\\mathcal{D}$ is separable with a $\\left(\\gamma,\\rho\\right)$-margin, then the sample complexity of Hard-SVM is\n",
    "\n",
    "$$m\\left(\\epsilon,\\delta\\right)\\leq \\frac{8}{\\epsilon^2}\\left(2\\left(\\frac{\\rho}{\\gamma}\\right)^2+\\log{\\frac{2}{\\delta}}\\right)$$\n",
    "\n",
    "Note that the sample complexity obtained by computing the VC dimension of half spaces in $d$ dimensions, we get that the sample complexity is $d$. While now we have found that the sample complexity does not depend on the dimension, but only on the $\\frac{\\rho}{\\gamma}$ ratio (and the accuracy $\\delta$ and the correctness $\\epsilon$)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### 1.1.2 Soft-SVM\n",
    "\n",
    "In the Hard-SVM settings we made the strong separability assumption, which needs to be relaxed in order to apply SVMs to real data. In order to relax this constraint, we introduce nonnegative slack variables $\\xi_1,\\dots,\\xi_m$, and we repace each constraint that was before $\\mathcal{y_i}\\left(\\left\\langle\\mathbf{w,x_i}\\right\\rangle+b\\right) \\geq 1$ with $\\mathcal{y_i}\\left(\\left\\langle\\mathbf{w,x_i}\\right\\rangle+b\\right) \\geq 1 - \\xi_i$. $\\xi_i$ measures by how much the constraint $\\mathcal{y_i}\\left(\\left\\langle\\mathbf{w,x_i}\\right\\rangle+b\\right) \\geq 1$ is being violated. The Soft-SVM rules then writes:\n",
    "\n",
    "```{admonition} Soft-SVM rule\n",
    ":class: important\n",
    "$$\\underset{\\left(\\mathbf{w}, b\\right)}{\\operatorname{argmin}}\\left(\\lambda\\left\\lVert\\mathbf{w}\\right\\rVert^2+\\frac{1}{m}\\overset{m}{\\underset{i=1}{\\sum}}\\xi_i\\right) \\operatorname{s.t.}\\ \\forall i,\\ \\mathcal{y_i}\\left(\\left\\langle\\mathbf{w, x_i}\\right\\rangle+b\\right)\\geq1\\wedge\\xi_i\\geq0\\tag{3}$$\n",
    "\n",
    "Note that now we also minimize the average violation of the constraint along with the norm\n",
    "```\n",
    "\n",
    "#### 1.1.3 Kernel Trick\n",
    "\n",
    "Note that there exists a dual formulation for the SVM problem:\n",
    "\n",
    "```{admonition} Hard-SVM Primal-Dual\n",
    ":class: important\n",
    "(Primal)\n",
    "\n",
    "$$\\underset{\\left(\\mathbf{w}, b\\right)}{\\operatorname{argmin}}\\left\\lVert\\mathbf{w}\\right\\rVert^2\\ \\operatorname{s.t.}\\ \\forall i,\\ \\mathcal{y_i}\\left\\langle\\mathbf{w, x_i}\\right\\rangle\\geq1\\tag{3}$$\n",
    "\n",
    "\n",
    "(Dual)\n",
    "\n",
    "$$\\underset{\\mathbf{\\alpha}\\in\\mathbb{R}^m:\\mathbf{\\alpha}\\geq\\mathbf{0}}{\\operatorname{max}}\\underset{\\mathbf{w}}{\\operatorname{min}}\\left(\\frac{1}{2}\\left\\lVert\\mathbf{w}^2\\right\\rVert+\\overset{m}{\\underset{i=1}{\\sum}}\\alpha_i\\left(1-y_i\\langle\\mathbf{w, x_i}\\rangle\\right)\\right)$$\n",
    "```\n",
    "\n",
    "We start by fixing $\\alpha$ and solving the inner optimization (we call it $Z$). Note that the inner minimization is the minimization of a hyperparaboloid in $w$, and in order to find the minimum, it is enough to find the vertex of the paraboloid, requiring the derivative equals 0\n",
    "\n",
    "$$\\nabla Z\\left(w\\right)=\\mathbf{w}-\\overset{m}{\\underset{i=1}{\\sum}}\\alpha_i y_i \\mathbf{x}_i$$\n",
    "\n",
    "$$\\mathbf{w}=\\overset{m}{\\underset{i=1}{\\sum}}\\alpha_i y_i \\mathbf{x}_i$$\n",
    "\n",
    "NOTE that this means that our solution is nothing more than a linear combination of our data. Plugging back the solution of the inner optimization, into the outer optimization, we obtain\n",
    "\n",
    "$$\\underset{\\mathbf{\\alpha}\\in\\mathbb{R}^m:\\mathbf{\\alpha}\\geq\\mathbf{0}}{\\operatorname{max}}\\left(\\overset{m}{\\underset{i=1}{\\sum}}\\alpha_i-\\frac{1}{2}\\overset{m}{\\underset{i,j=1}{\\sum}} \\alpha_i\\alpha_j y_i y_j \\left\\langle\\mathbf{x_i, x_j}\\right\\rangle  \\right)$$\n",
    "\n",
    "The problem now is entirely dependent on the inner product of $\\left\\langle\\mathbf{x_i, x_j}\\right\\rangle$. We introudce the concept of *GRAM MATRIX* which is essentially a matrix of inner products defined as \n",
    "\n",
    "\n",
    "```{admonition} Gram Matrix\n",
    ":class: important\n",
    "We call Gram Matrix of ${\\mathbf{x_i},\\dots,\\mathbf{x_m}}$ the matrix $G=\\left(G_{ij}\\right)\\ \\operatorname{s.t.}\\ G_{ij}=\\left\\langle\\mathbf{x_i, x_j}\\right\\rangle$\n",
    "```\n",
    "\n",
    "And we can now say that our problem is entirely controlled by the entries of the Gram Matrix. Now that we have this new formulation of the SVM, we can make a step further, and think to those situations where the points are not linearly separable in the original representation (space). The solution to this is to find some *feature space* where our data is actually linearly separable, and train our linear model in that space. In order to reach that space, we need a *mapping function* \n",
    "\n",
    "\n",
    "$$\\psi: \\mathcal{X}\\rightarrow\\mathcal{H} \\left(\\text{e.g.}\\psi\\left(x\\right)=\\left(x,x^2\\right)\\right)$$ \n",
    "\n",
    "Where $\\mathcal{H}$ is a special space called *Hilbert Space*. Our solution turns into $\\mathbf{w}=\\underset{i}{\\sum}\\alpha_i\\psi\\left(\\mathbf{x}_i\\right)$, while the entry of our Gram matrix now looks like $G_{ij}=\\left\\langle\\psi\\left(\\mathbf{x}_i\\right),\\psi\\left(\\mathbf{x}_j\\right)\\right\\rangle$\n",
    "\n",
    "This is an important result, but it carries with it some computational issues (it is expensive to compute the full Gram matrix for any mapping function). To make this feasible we consider *Mercer's conditions*:\n",
    "\n",
    "```{admonition} Mercer's Conditions\n",
    ":class: important\n",
    "A symmetric function (that is $K\\left(\\mathbf{x,x^\\prime}\\right)=K\\left(\\mathbf{x^\\prime,x}\\right)\\ \\forall x,x^\\prime$) $K:\\mathcal{X}\\times\\mathcal{X}\\rightarrow\\mathbb{R}$ implements an inner product in some Hilbert space, (that is $\\exists\\psi:\\mathcal{X}\\rightarrow\\mathcal{H}:k\\left(\\mathbf{x,x^\\prime}\\right)=\\left\\langle\\psi\\left(\\mathbf{x_i}\\right),\\psi\\left(\\mathbf{x_J}\\right)\\right\\rangle$ if and only if it is positive semidefinite.\n",
    "```\n",
    "\n",
    "This allows to replace the dot product in the feature space, with the evaluation of $K$ on the points in the starting representation, making this approach viable computationally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-maker",
   "metadata": {},
   "source": [
    "### 1.2 Application\n",
    "\n",
    "We now use the code we showed in the previous section and perform grid-search cross-validation using the Sklearn's implementation of the Soft-SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-jenny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-pharmacy",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('./dataset/online_shoppers_intention.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train, y_train = df_train.drop(columns='Revenue'), df_train['Revenue']\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "textual_columns = ['Month', 'VisitorType', 'Weekend']\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "numerical_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "        ('OrdinalEncoder', OrdinalEncoder(), textual_columns),\n",
    "        ('MinMaxScaler', MinMaxScaler(), numerical_columns),\n",
    "#         ('OneHotEncoder', OneHotEncoder(), categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "categorical_features = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "categorical_indices = [c in categorical_features for c in df_train.columns]\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('ColumnTransformer', column_transformer),\n",
    "        ('SMOTENC', SMOTENC(categorical_features=categorical_indices)),\n",
    "        ('Classifier', SVC())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-brake",
   "metadata": {},
   "source": [
    "Below there is a list of the parameters accepted by Sklearn's Support Vector Classifiers\n",
    "\n",
    "* **C**: A value inversely proportional the amount of slack we want to allow.\n",
    "* **kernel**: The kernel function used to *compute* the inner products in the feature space.\n",
    "* **gamma**: A coefficient multiplying the kernel function. Intuitively is the inverse of the radius of influence of samples seleced as support vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fossil-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([14.50913711,  9.28047853, 28.24448862,  7.54544597]),\n",
       " 'std_fit_time': array([0.76036667, 0.59917796, 1.20778518, 0.31240662]),\n",
       " 'mean_score_time': array([0.33443379, 1.00192018, 0.23313251, 0.48394966]),\n",
       " 'std_score_time': array([0.07504759, 0.37212613, 0.01457453, 0.02145307]),\n",
       " 'param_Classifier__C': masked_array(data=[1, 1, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__gamma': masked_array(data=['auto', 'auto', 'auto', 'auto'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'Classifier__C': 1,\n",
       "   'Classifier__gamma': 'auto',\n",
       "   'Classifier__kernel': 'linear'},\n",
       "  {'Classifier__C': 1,\n",
       "   'Classifier__gamma': 'auto',\n",
       "   'Classifier__kernel': 'rbf'},\n",
       "  {'Classifier__C': 10,\n",
       "   'Classifier__gamma': 'auto',\n",
       "   'Classifier__kernel': 'linear'},\n",
       "  {'Classifier__C': 10,\n",
       "   'Classifier__gamma': 'auto',\n",
       "   'Classifier__kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.80030411, 0.70805879, 0.82767359, 0.78611252]),\n",
       " 'split1_test_score': array([0.81753675, 0.73137354, 0.82716675, 0.79270147]),\n",
       " 'split2_test_score': array([0.80435884, 0.70603142, 0.82970096, 0.77445514]),\n",
       " 'split3_test_score': array([0.80030411, 0.7141409 , 0.82260517, 0.78813989]),\n",
       " 'split4_test_score': array([0.7530426 , 0.68965517, 0.79158215, 0.75557809]),\n",
       " 'mean_test_score': array([0.79510928, 0.70985197, 0.81974573, 0.77939742]),\n",
       " 'std_test_score': array([0.02196417, 0.01347068, 0.0142716 , 0.01334397]),\n",
       " 'rank_test_score': array([2, 4, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we define the subset of parameters to use in the gridsearch model selection technique\n",
    "param_grid = [\n",
    "    {\n",
    "        'Classifier__C': [1, 10],\n",
    "        'Classifier__kernel': ['linear', 'rbf'],\n",
    "        'Classifier__gamma': ['auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# linear_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=6, verbose=5).fit(x_train, y_train)\n",
    "# linear_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-compatibility",
   "metadata": {},
   "source": [
    "## 2. Trees and Random Forests\n",
    "\n",
    "Decision trees are predictors that assign labels to samples by travelling across a tree, from root to leaf. On each node, the next child is chosen by splitting the input space.\n",
    "\n",
    "The most common splitting rule for an internal node of the tree is a thresold on the value of a single feature (e.g. temperature>40). This means that we move to either one of the child on the basis of $\\mathbb{1}_\\left[x_i<\\theta\\right]$ where $i \\in \\left[d\\right]$ is the index of the feature currently being analyzed, and $\\theta\\in\\mathbb{R}$ is the threshold value. We can think of a decision tree as a splitting of the input space $\\mathcal{X}\\in\\mathbb{R}^d$, into as many cells as there are leaf nodes. It is clear then that the tree with $k$ leaves shatters a set of cardinality $k$. It follows that an infinitely tall tree, with infinite number of leafs, has an infinite VC dimension. This can cause overfitting. For this reason we must adopt some methods to learn smaller trees, that will tend to overfit less, but have a higher empirical risk.\n",
    "\n",
    "### 2.1. Growing a Tree\n",
    "\n",
    "When building a tree, we start from the whole training set. Then we build recursively either a child or a leaf. Leafs are built when the labels of the remaining training set have all the same label (we are in a binary classification example) or when we have no samples left, while children are built when the remaining samples have mixed labels. When a child node is required, the threhold rule is built by considering some *Gain measure*, where we select the threshold on the feature that produces the maximum gain over the remaining samples. We then generate the two new children, and split our training set on the newly found feature with the newly found threshold. We go on until we encounter a leaf, and then backtrack.\n",
    "\n",
    "This technique tends to build very big trees, for this reason some pruning techniques must be applied to limit the overfitting.\n",
    "\n",
    "### 2.2. From Trees to Forests\n",
    "\n",
    "A Random Forest is an *ensamble* of trees. Each tree is built by applying the same algorithm $A$ over a training set $S^\\prime$ obtained by uniform sampling over $S$ with replacement (*bagging*). Since if we only applied bagging to the samples, we would end up with very similarly structured tree (the first split would always be the same with respect to some metric), we also need to apply *feature bagging*. So we sample the *features* to be used, by choosing $k$ features uniformly among the starting $d$ features.\n",
    "\n",
    "### 2.3 Bagging and CV\n",
    "\n",
    "When applying the random forest algorithm with cross validation (and grid seach) the whole process becomes quite hard to picture, for this reason, below there is a visual recap of the whole process\n",
    "\n",
    "![trees_cv](images/trees-cv.png)\n",
    "\n",
    "\n",
    "### 2.4 Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "headed-investor",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('./dataset/online_shoppers_intention.csv')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train, y_train = df_train.drop(columns='Revenue'), df_train['Revenue']\n",
    "x_test, y_test = df_test.drop(columns='Revenue'), df_test['Revenue']\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "textual_columns = ['Month', 'VisitorType', 'Weekend']\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "numerical_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "        ('OrdinalEncoder', OrdinalEncoder(), textual_columns),\n",
    "        ('MinMaxScaler', MinMaxScaler(), numerical_columns),\n",
    "#         ('OneHotEncoder', OneHotEncoder(), categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "categorical_features = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "categorical_indices = [c in categorical_features for c in df_train.columns]\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('ColumnTransformer', column_transformer),\n",
    "        ('SMOTENC', SMOTENC(categorical_features=categorical_indices)),\n",
    "        ('Classifier', RandomForestClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-secret",
   "metadata": {},
   "source": [
    "\n",
    "Below there is a list of the parameters accepted by Sklearn's Support Vector Classifiers\n",
    "​\n",
    "* **n_estimators**: The number of trees to grow inside the forest.\n",
    "* **criterion**: The criterion used to perform the split in the nodes.\n",
    "* **max_depth**: Limits the size of the tree (lower values reduce overfitting)\n",
    "* **min_samples_split**: The mimimum amount of samples in a node to allow a further split (high values reduce overfitting)\n",
    "* **min_samples_leaf**: The minimum number of samples in both branches for a given node (high values reduce overfitting)\n",
    "* **max_features**: The maximum number of features to use when splitting the nodes (maximum size for feature bagging)\n",
    "* **bootrtrap**: Whether to use bootstrap when buildig trees, or use the entire dataset each time.\n",
    "* **oob_score**: Whether to use out-of-bag-samples to estimate the generalization score. (not sure how it works when applying cross validation)\n",
    "​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "returning-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicola/.pyenv/versions/3.8.5/envs/cuda/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/nicola/.pyenv/versions/3.8.5/envs/cuda/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.53937278, 3.32089152, 3.30840521, 3.31740518, 3.33078213,\n",
       "        2.83384309, 2.74559731, 2.81040087, 3.01606846, 2.82516623,\n",
       "        2.97552195, 2.86001577, 2.70931211, 2.70091052, 2.77443328,\n",
       "        2.83074532, 3.05245662, 2.80835638, 2.79700241, 2.76745524,\n",
       "        2.80897598, 2.8449832 , 3.29542537, 3.17432795, 2.74272118,\n",
       "        2.69943991, 2.81082621, 2.82444029, 3.20742917, 3.13249292,\n",
       "        2.60044937, 2.74732041, 2.97075377, 3.02657061, 3.35369229,\n",
       "        3.2580997 , 2.82707038, 3.01725712, 3.04608479, 2.98724403,\n",
       "        3.60329595, 3.6450161 , 2.94896793, 2.73229456, 2.81019559,\n",
       "        2.74060569, 3.3525013 , 3.3840477 , 2.75313869, 2.68272214,\n",
       "        2.79580631, 2.81417136, 3.38447905, 3.37404242, 2.65339823,\n",
       "        2.65083256, 2.71974273, 2.73724213, 2.84515038, 2.81925492,\n",
       "        2.71091576, 2.72139802, 2.84052105, 2.78002048, 2.85081701,\n",
       "        2.77455492, 2.76483893, 2.81413236, 2.77616639, 2.7542747 ,\n",
       "        2.92765484, 2.8393249 , 2.69738631, 2.63262396, 3.0603538 ,\n",
       "        2.88601141, 3.49799104, 3.43321767, 3.09761004, 3.02173905,\n",
       "        3.12834496, 2.96515789, 3.39394279, 3.36162801, 2.64614215,\n",
       "        2.92856555, 2.91199727, 2.79092236, 3.25438457, 3.26194043,\n",
       "        2.71696153, 2.81089339, 2.92702265, 2.76355658, 3.47556057,\n",
       "        3.46537061, 2.72799921, 2.81393061, 2.80330257, 2.76810598,\n",
       "        3.43901763, 3.43046956, 2.70252576, 2.80010309, 2.99578829,\n",
       "        3.14526548, 3.69513903, 3.29483309]),\n",
       " 'std_fit_time': array([0.53813507, 0.3531128 , 0.41841401, 0.56560059, 0.44565817,\n",
       "        0.06823893, 0.07208334, 0.07408511, 0.22852303, 0.12077699,\n",
       "        0.09416116, 0.04131682, 0.06714294, 0.03066592, 0.05554207,\n",
       "        0.14788022, 0.27771244, 0.06426809, 0.08914072, 0.08781248,\n",
       "        0.10379747, 0.08248209, 0.13635313, 0.04402764, 0.19477172,\n",
       "        0.17080894, 0.05116171, 0.06474714, 0.05989215, 0.05405853,\n",
       "        0.07059519, 0.07745821, 0.17256512, 0.27430621, 0.26435063,\n",
       "        0.0730508 , 0.10771474, 0.05634942, 0.12924905, 0.0725482 ,\n",
       "        0.06728537, 0.42097055, 0.31790086, 0.04481647, 0.07576098,\n",
       "        0.07426022, 0.03697953, 0.28231721, 0.27024617, 0.05594495,\n",
       "        0.04473794, 0.05747263, 0.03065005, 0.05327456, 0.0478229 ,\n",
       "        0.07937823, 0.0476006 , 0.03826104, 0.08132647, 0.06940851,\n",
       "        0.06898329, 0.1127447 , 0.06184042, 0.11781213, 0.11799218,\n",
       "        0.03837685, 0.20951513, 0.26905568, 0.14891922, 0.11826649,\n",
       "        0.15744234, 0.07018401, 0.07904082, 0.0655622 , 0.26808007,\n",
       "        0.11246134, 0.05670081, 0.1317485 , 0.47310915, 0.55836009,\n",
       "        0.38952961, 0.0762683 , 0.10621981, 0.08863796, 0.10334443,\n",
       "        0.33617876, 0.28802837, 0.06199811, 0.04976698, 0.07371356,\n",
       "        0.12742634, 0.13361939, 0.09832116, 0.02852843, 0.05836077,\n",
       "        0.11399239, 0.13564833, 0.16675596, 0.08828432, 0.08003034,\n",
       "        0.04343399, 0.02104688, 0.11651972, 0.1414132 , 0.0922745 ,\n",
       "        0.12082243, 0.15762584, 0.20906711]),\n",
       " 'mean_score_time': array([0.01032143, 0.00739131, 0.00909791, 0.00890255, 0.01228948,\n",
       "        0.0143681 , 0.00755839, 0.0081532 , 0.00880361, 0.00690718,\n",
       "        0.01271181, 0.01265135, 0.00567846, 0.00563364, 0.00781574,\n",
       "        0.00785942, 0.01396651, 0.01287284, 0.00951142, 0.00735579,\n",
       "        0.00876193, 0.00783644, 0.0177381 , 0.0172256 , 0.00558524,\n",
       "        0.00589499, 0.00834804, 0.00797677, 0.01762066, 0.01772351,\n",
       "        0.00695543, 0.00554986, 0.01017346, 0.00821157, 0.01835732,\n",
       "        0.01699686, 0.00832796, 0.00678558, 0.00972896, 0.00999193,\n",
       "        0.02411919, 0.02563262, 0.00640101, 0.00686517, 0.00972075,\n",
       "        0.00978804, 0.02218938, 0.02072525, 0.00603189, 0.00658927,\n",
       "        0.00940895, 0.01121254, 0.02016764, 0.02392759, 0.00690227,\n",
       "        0.00537777, 0.00724354, 0.0071075 , 0.01259913, 0.01191154,\n",
       "        0.00651827, 0.00718851, 0.00718517, 0.00791206, 0.01318226,\n",
       "        0.01303053, 0.00652637, 0.00552278, 0.00837426, 0.00747285,\n",
       "        0.01332531, 0.0131556 , 0.00670838, 0.00531397, 0.00866442,\n",
       "        0.00967402, 0.02081132, 0.02298851, 0.00606108, 0.00723066,\n",
       "        0.00831819, 0.00867229, 0.01800156, 0.01817827, 0.00769906,\n",
       "        0.00557809, 0.00946112, 0.00900426, 0.01793156, 0.01940145,\n",
       "        0.00600691, 0.00614748, 0.00803304, 0.00895505, 0.01933155,\n",
       "        0.02302346, 0.00670652, 0.00609646, 0.00780201, 0.00880103,\n",
       "        0.01879601, 0.02257028, 0.00695167, 0.00759916, 0.01284475,\n",
       "        0.01040158, 0.01946449, 0.01859837]),\n",
       " 'std_score_time': array([0.00314225, 0.00237714, 0.00199677, 0.00235131, 0.00163688,\n",
       "        0.00393014, 0.0025369 , 0.00279507, 0.00166327, 0.00103584,\n",
       "        0.00118271, 0.00157793, 0.00163493, 0.00054651, 0.00193545,\n",
       "        0.00174679, 0.002079  , 0.00157044, 0.0019351 , 0.00166791,\n",
       "        0.00134372, 0.00057715, 0.00117037, 0.00112009, 0.00039741,\n",
       "        0.00094806, 0.00158215, 0.00154899, 0.00088242, 0.00129723,\n",
       "        0.00194612, 0.00030978, 0.00430552, 0.00084132, 0.00191116,\n",
       "        0.00083734, 0.00557596, 0.00336465, 0.00236846, 0.00228195,\n",
       "        0.00250486, 0.00428003, 0.00053073, 0.00162041, 0.0023593 ,\n",
       "        0.00147432, 0.00310371, 0.00184199, 0.00169083, 0.00079024,\n",
       "        0.00194813, 0.0050961 , 0.00156729, 0.00549948, 0.00170732,\n",
       "        0.00039625, 0.00082798, 0.00066038, 0.00083972, 0.00070048,\n",
       "        0.0009067 , 0.0025505 , 0.00087946, 0.00173378, 0.00188879,\n",
       "        0.00206756, 0.00094634, 0.0006233 , 0.00193223, 0.00163681,\n",
       "        0.00251406, 0.00109085, 0.00129247, 0.00065168, 0.00219297,\n",
       "        0.00171949, 0.00439429, 0.0040724 , 0.00111203, 0.00212468,\n",
       "        0.00049328, 0.00190319, 0.00113288, 0.00267072, 0.00146752,\n",
       "        0.00088884, 0.00087293, 0.00197163, 0.00189225, 0.00341882,\n",
       "        0.00086106, 0.0018926 , 0.00089367, 0.00072392, 0.00067955,\n",
       "        0.00441273, 0.00285239, 0.00077361, 0.00019674, 0.00182968,\n",
       "        0.00044927, 0.0052298 , 0.00357137, 0.00217592, 0.00371702,\n",
       "        0.00218343, 0.00058968, 0.00045982]),\n",
       " 'param_Classifier__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__n_estimators': masked_array(data=[1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10,\n",
       "                    10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50,\n",
       "                    1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10,\n",
       "                    10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50,\n",
       "                    1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10,\n",
       "                    10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50,\n",
       "                    1, 1, 10, 10, 50, 50, 1, 1, 10, 10, 50, 50, 1, 1, 10,\n",
       "                    10, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__oob_score': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_Classifier__random_state': masked_array(data=[42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "                    42, 42, 42, 42, 42, 42, 42, 42, 42, 42],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'gini',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 1,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 10,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'auto',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'sqrt',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 1,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 10,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': True,\n",
       "   'Classifier__random_state': 42},\n",
       "  {'Classifier__criterion': 'entropy',\n",
       "   'Classifier__max_depth': 50,\n",
       "   'Classifier__max_features': 'log2',\n",
       "   'Classifier__n_estimators': 50,\n",
       "   'Classifier__oob_score': False,\n",
       "   'Classifier__random_state': 42}],\n",
       " 'split0_test_score': array([0.41409022, 0.40598074, 0.61530664, 0.64622402, 0.71059301,\n",
       "        0.69640142, 0.44247339, 0.44247339, 0.61581348, 0.62696401,\n",
       "        0.70146984, 0.69842879, 0.43233654, 0.40446021, 0.61784085,\n",
       "        0.64014192, 0.700963  , 0.70704511, 0.78256462, 0.79523568,\n",
       "        0.85149518, 0.85301571, 0.8540294 , 0.85554992, 0.82209833,\n",
       "        0.82260517, 0.86011151, 0.8504815 , 0.85859098, 0.86011151,\n",
       "        0.81652306, 0.82716675, 0.85200203, 0.85656361, 0.85504308,\n",
       "        0.85554992, 0.80689306, 0.82007096, 0.86213887, 0.87176888,\n",
       "        0.8707552 , 0.87126204, 0.80790674, 0.82665991, 0.87278256,\n",
       "        0.8707552 , 0.87227572, 0.87633046, 0.80689306, 0.82919412,\n",
       "        0.87176888, 0.87227572, 0.86822098, 0.87278256, 0.41409022,\n",
       "        0.43233654, 0.61530664, 0.6112519 , 0.69437405, 0.69386721,\n",
       "        0.45463761, 0.34465281, 0.59401926, 0.63811455, 0.69893563,\n",
       "        0.69589458, 0.4318297 , 0.40851495, 0.60618348, 0.59858084,\n",
       "        0.69437405, 0.69285352, 0.79726305, 0.81500253, 0.8469336 ,\n",
       "        0.84946782, 0.84541308, 0.85656361, 0.81550938, 0.80587937,\n",
       "        0.84896097, 0.85200203, 0.85605677, 0.85656361, 0.82463254,\n",
       "        0.81601622, 0.85352255, 0.84490623, 0.85909782, 0.85707045,\n",
       "        0.81500253, 0.80638621, 0.87430309, 0.87126204, 0.88139888,\n",
       "        0.87126204, 0.80435884, 0.83223517, 0.87582362, 0.86974151,\n",
       "        0.87430309, 0.87379625, 0.81956412, 0.80993411, 0.86112519,\n",
       "        0.87430309, 0.86872783, 0.87633046]),\n",
       " 'split1_test_score': array([0.39989863, 0.42676128, 0.59908768, 0.60922453, 0.68930563,\n",
       "        0.68930563, 0.33147491, 0.42676128, 0.61733401, 0.62088191,\n",
       "        0.69589458, 0.69031931, 0.42676128, 0.41713127, 0.59756716,\n",
       "        0.61074506, 0.68575773, 0.69386721, 0.794222  , 0.79118094,\n",
       "        0.83476939, 0.83983781, 0.84744045, 0.84794729, 0.81196148,\n",
       "        0.8170299 , 0.83476939, 0.83882413, 0.8373036 , 0.83831728,\n",
       "        0.79827674, 0.81500253, 0.83882413, 0.84186518, 0.84287886,\n",
       "        0.84135834, 0.80689306, 0.80233147, 0.8540294 , 0.86264572,\n",
       "        0.8672073 , 0.86061835, 0.80081095, 0.80435884, 0.86163203,\n",
       "        0.86011151, 0.85707045, 0.86061835, 0.80892043, 0.80993411,\n",
       "        0.85554992, 0.86568677, 0.86467309, 0.86315256, 0.42676128,\n",
       "        0.42676128, 0.60060821, 0.60973137, 0.67866194, 0.67866194,\n",
       "        0.39989863, 0.32843386, 0.58692347, 0.59553979, 0.68930563,\n",
       "        0.6710593 , 0.34668018, 0.39077547, 0.60466295, 0.60364927,\n",
       "        0.68626457, 0.68626457, 0.81855043, 0.81196148, 0.83324886,\n",
       "        0.83274202, 0.83527623, 0.84287886, 0.82513938, 0.81449569,\n",
       "        0.84591992, 0.82868728, 0.83882413, 0.84389255, 0.81753675,\n",
       "        0.80841358, 0.83679676, 0.83679676, 0.8408515 , 0.83679676,\n",
       "        0.78509883, 0.78560568, 0.85149518, 0.85757729, 0.86619361,\n",
       "        0.86061835, 0.80993411, 0.8170299 , 0.86923467, 0.85554992,\n",
       "        0.86771414, 0.86061835, 0.82564622, 0.80131779, 0.86112519,\n",
       "        0.86112519, 0.86213887, 0.86467309]),\n",
       " 'split2_test_score': array([0.40040547, 0.4054739 , 0.56867714, 0.57273188, 0.70146984,\n",
       "        0.7045109 , 0.43335023, 0.39077547, 0.59604663, 0.55854029,\n",
       "        0.70400405, 0.71819564, 0.40040547, 0.37354283, 0.62290928,\n",
       "        0.5945261 , 0.70755195, 0.71160669, 0.83831728, 0.8109478 ,\n",
       "        0.86771414, 0.8636594 , 0.86315256, 0.87328941, 0.82919412,\n",
       "        0.82361885, 0.86517993, 0.86112519, 0.86771414, 0.86872783,\n",
       "        0.79574252, 0.79016726, 0.87024835, 0.85960466, 0.87024835,\n",
       "        0.86467309, 0.82007096, 0.82513938, 0.87886467, 0.87937152,\n",
       "        0.88646731, 0.88849468, 0.81246832, 0.82513938, 0.88646731,\n",
       "        0.87835783, 0.8803852 , 0.8839331 , 0.81348201, 0.80131779,\n",
       "        0.87937152, 0.88342625, 0.88697415, 0.88748099, 0.3421186 ,\n",
       "        0.4054739 , 0.57374557, 0.60212874, 0.69893563, 0.6974151 ,\n",
       "        0.40496706, 0.37354283, 0.6112519 , 0.58185504, 0.70603142,\n",
       "        0.69285352, 0.37404967, 0.3755702 , 0.59553979, 0.58590978,\n",
       "        0.70603142, 0.7045109 , 0.79523568, 0.81297516, 0.86315256,\n",
       "        0.87024835, 0.87278256, 0.86872783, 0.81398885, 0.82007096,\n",
       "        0.85909782, 0.86416624, 0.86670046, 0.87379625, 0.82868728,\n",
       "        0.81398885, 0.86315256, 0.86771414, 0.86872783, 0.86416624,\n",
       "        0.81956412, 0.81550938, 0.88241257, 0.88139888, 0.88291941,\n",
       "        0.88646731, 0.81652306, 0.8170299 , 0.8839331 , 0.87176888,\n",
       "        0.88241257, 0.88494678, 0.8241257 , 0.83426254, 0.88798784,\n",
       "        0.88190573, 0.88241257, 0.88950836]),\n",
       " 'split3_test_score': array([0.37100862, 0.3852002 , 0.6147998 , 0.57475925, 0.68727826,\n",
       "        0.68677141, 0.37100862, 0.37100862, 0.607704  , 0.58996452,\n",
       "        0.69488089, 0.68018246, 0.41561075, 0.41561075, 0.59148505,\n",
       "        0.58590978, 0.68525089, 0.68626457, 0.78864673, 0.77192093,\n",
       "        0.83426254, 0.83223517, 0.84135834, 0.84541308, 0.79016726,\n",
       "        0.80841358, 0.84034465, 0.8337557 , 0.84439939, 0.84135834,\n",
       "        0.79219463, 0.78915357, 0.84034465, 0.83578307, 0.83831728,\n",
       "        0.8469336 , 0.79371515, 0.79523568, 0.85352255, 0.8540294 ,\n",
       "        0.86011151, 0.86264572, 0.80283832, 0.80537253, 0.85757729,\n",
       "        0.85707045, 0.85656361, 0.86264572, 0.78205778, 0.78966042,\n",
       "        0.85859098, 0.85504308, 0.85859098, 0.86011151, 0.37100862,\n",
       "        0.37100862, 0.57982767, 0.56867714, 0.6842372 , 0.68575773,\n",
       "        0.40446021, 0.3852002 , 0.57729346, 0.57932083, 0.67257983,\n",
       "        0.6746072 , 0.41561075, 0.37100862, 0.58945768, 0.54637608,\n",
       "        0.67866194, 0.68626457, 0.79574252, 0.79979726, 0.84591992,\n",
       "        0.82868728, 0.83781044, 0.83882413, 0.794222  , 0.78763305,\n",
       "        0.83933097, 0.83071465, 0.84338571, 0.84135834, 0.78459199,\n",
       "        0.80030411, 0.8373036 , 0.84439939, 0.84287886, 0.84186518,\n",
       "        0.80587937, 0.78509883, 0.85301571, 0.85909782, 0.86011151,\n",
       "        0.86315256, 0.78509883, 0.80131779, 0.85808414, 0.85504308,\n",
       "        0.85859098, 0.8636594 , 0.80435884, 0.79726305, 0.85504308,\n",
       "        0.84794729, 0.86011151, 0.86163203]),\n",
       " 'split4_test_score': array([0.39097363, 0.418357  , 0.59229209, 0.59127789, 0.71399594,\n",
       "        0.70740365, 0.418357  , 0.418357  , 0.61054767, 0.63894523,\n",
       "        0.71146045, 0.71196755, 0.418357  , 0.418357  , 0.59127789,\n",
       "        0.58975659, 0.70638945, 0.71146045, 0.79868154, 0.79817444,\n",
       "        0.84837728, 0.84229209, 0.85598377, 0.85851927, 0.79310345,\n",
       "        0.79361055, 0.85344828, 0.85243408, 0.84989858, 0.85395538,\n",
       "        0.79868154, 0.81744422, 0.84888438, 0.85496957, 0.85344828,\n",
       "        0.85851927, 0.80780933, 0.80578093, 0.87423935, 0.86916836,\n",
       "        0.86866126, 0.86764706, 0.81338742, 0.81338742, 0.87271805,\n",
       "        0.87474645, 0.86967546, 0.86916836, 0.81135903, 0.81389452,\n",
       "        0.87018256, 0.86916836, 0.87423935, 0.86511156, 0.37880325,\n",
       "        0.418357  , 0.60192698, 0.59989858, 0.70638945, 0.70182556,\n",
       "        0.418357  , 0.42444219, 0.58975659, 0.60598377, 0.70030426,\n",
       "        0.70892495, 0.37119675, 0.37880325, 0.60446247, 0.61409736,\n",
       "        0.70283976, 0.70841785, 0.8311359 , 0.82657201, 0.85496957,\n",
       "        0.85851927, 0.85496957, 0.85141988, 0.80527383, 0.80983773,\n",
       "        0.85243408, 0.85141988, 0.85141988, 0.85294118, 0.80476673,\n",
       "        0.80831643, 0.84685598, 0.84989858, 0.84939148, 0.84787018,\n",
       "        0.82860041, 0.80628803, 0.88184584, 0.87170385, 0.86764706,\n",
       "        0.87068966, 0.81085193, 0.82403651, 0.87271805, 0.86612576,\n",
       "        0.87068966, 0.86916836, 0.81947262, 0.82454361, 0.87119675,\n",
       "        0.86967546, 0.87018256, 0.86713996]),\n",
       " 'mean_test_score': array([0.39527531, 0.40835462, 0.59803267, 0.59884352, 0.70052853,\n",
       "        0.6968786 , 0.39933283, 0.40987515, 0.60948916, 0.60705919,\n",
       "        0.70154196, 0.69981875, 0.41869421, 0.40582041, 0.60421604,\n",
       "        0.60421589, 0.6971826 , 0.7020488 , 0.80048644, 0.79349196,\n",
       "        0.84732371, 0.84620804, 0.8523929 , 0.85614379, 0.80930493,\n",
       "        0.81305561, 0.85077075, 0.84732412, 0.85158134, 0.85249407,\n",
       "        0.8002837 , 0.80778687, 0.85006071, 0.84975722, 0.85198717,\n",
       "        0.85340684, 0.80707631, 0.80971169, 0.86455897, 0.86739677,\n",
       "        0.87064051, 0.87013357, 0.80748235, 0.81498362, 0.87023545,\n",
       "        0.86820829, 0.86719409, 0.8705392 , 0.80454246, 0.80880019,\n",
       "        0.86709277, 0.86912004, 0.87053971, 0.86972784, 0.38655639,\n",
       "        0.41078747, 0.59428301, 0.59833755, 0.69251965, 0.69150551,\n",
       "        0.4164641 , 0.37125438, 0.59184894, 0.6001628 , 0.69343135,\n",
       "        0.68866791, 0.38787341, 0.3849345 , 0.60006127, 0.58972267,\n",
       "        0.69363435, 0.69566228, 0.80758552, 0.81326169, 0.8488449 ,\n",
       "        0.84793295, 0.84925038, 0.85168286, 0.81082669, 0.80758336,\n",
       "        0.84914875, 0.84539802, 0.85127739, 0.85371038, 0.81204306,\n",
       "        0.80940784, 0.84752629, 0.84874302, 0.8521895 , 0.84955376,\n",
       "        0.81082905, 0.79977763, 0.86861448, 0.86820798, 0.87165409,\n",
       "        0.87043798, 0.80535336, 0.81832986, 0.87195871, 0.86364583,\n",
       "        0.87074209, 0.87043783, 0.8186335 , 0.81346422, 0.86729561,\n",
       "        0.86699135, 0.86871467, 0.87185678]),\n",
       " 'std_test_score': array([0.01420613, 0.01406352, 0.01717755, 0.02709903, 0.01081734,\n",
       "        0.00810878, 0.04192176, 0.02567152, 0.0075703 , 0.02915579,\n",
       "        0.00601176, 0.01387846, 0.01091137, 0.01687984, 0.0134815 ,\n",
       "        0.01985642, 0.00979259, 0.0102076 , 0.01967254, 0.01265166,\n",
       "        0.01234898, 0.01097315, 0.00745159, 0.00982139, 0.01545993,\n",
       "        0.01111962, 0.01154808, 0.00982753, 0.01065522, 0.01139018,\n",
       "        0.00844236, 0.01535292, 0.01125483, 0.00925234, 0.01108847,\n",
       "        0.00830334, 0.00834249, 0.01117856, 0.01036238, 0.0085663 ,\n",
       "        0.00868407, 0.00991155, 0.00501965, 0.00945814, 0.01010319,\n",
       "        0.0082687 , 0.00918129, 0.00866654, 0.01145979, 0.0131565 ,\n",
       "        0.00880566, 0.00921495, 0.00965758, 0.0098135 , 0.03049953,\n",
       "        0.02185138, 0.01530474, 0.01544765, 0.00997607, 0.00830661,\n",
       "        0.02005737, 0.03337636, 0.01115065, 0.02128451, 0.01173118,\n",
       "        0.01405602, 0.03120129, 0.01348605, 0.00649473, 0.02349471,\n",
       "        0.01017311, 0.00922524, 0.01465727, 0.0085236 , 0.00997663,\n",
       "        0.01557924, 0.01361871, 0.01055726, 0.0104243 , 0.01104284,\n",
       "        0.0065822 , 0.01361596, 0.00977851, 0.01149902, 0.01595125,\n",
       "        0.005472  , 0.01000211, 0.01036861, 0.01043368, 0.00994701,\n",
       "        0.01480597, 0.01224629, 0.013669  , 0.00884935, 0.00895514,\n",
       "        0.00902424, 0.01083711, 0.01018542, 0.00847141, 0.00705468,\n",
       "        0.00781923, 0.00855301, 0.00754557, 0.01398427, 0.0115729 ,\n",
       "        0.01166356, 0.00783636, 0.01009942]),\n",
       " 'rank_test_score': array([104, 101,  93,  91,  75,  78, 103, 100,  85,  86,  74,  76,  97,\n",
       "        102,  87,  88,  77,  73,  69,  72,  46,  47,  29,  25,  60,  54,\n",
       "         35,  45,  33,  28,  70,  62,  36,  37,  31,  27,  66,  58,  23,\n",
       "         18,   5,  11,  65,  51,  10,  16,  20,   7,  68,  61,  21,  13,\n",
       "          6,  12, 106,  99,  94,  92,  82,  83,  98, 108,  95,  89,  81,\n",
       "         84, 105, 107,  90,  96,  80,  79,  63,  53,  41,  43,  39,  32,\n",
       "         57,  64,  40,  48,  34,  26,  55,  59,  44,  42,  30,  38,  56,\n",
       "         71,  15,  17,   3,   8,  67,  50,   1,  24,   4,   9,  49,  52,\n",
       "         19,  22,  14,   2], dtype=int32)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here we define the subset of parameters to use in the gridsearch model selection technique\n",
    "param_grid = [\n",
    "    {\n",
    "        'Classifier__n_estimators': [1, 10, 50],\n",
    "        'Classifier__criterion': ['gini', 'entropy'],\n",
    "        'Classifier__max_depth': [1, 10, 50],\n",
    "        'Classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'Classifier__oob_score': [True, False],\n",
    "        'Classifier__random_state': [42]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Since I have to run every notebook each time I want to update the whole jupyter-book, and I have very limited computational\n",
    "# resources, I will comment the actual training and report only the best configuration found.\n",
    "# Since I fixed the random state, it should be very easy to reproduce the results.\n",
    "\n",
    "linear_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=6, verbose=5).fit(x_train, y_train)\n",
    "linear_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "worth-animation",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model & score\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 50,\n",
      " 'max_features': 'auto',\n",
      " 'n_estimators': 50,\n",
      " 'oob_score': True,\n",
      " 'random_state': 42}\n",
      "0.8687141522110355\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print('best model & score')\n",
    "# pprint(linear_search.best_params_, compact=True)\n",
    "# print(linear_search.best_score_)\n",
    "best_params = {'criterion': 'gini',\n",
    " 'max_depth': 50,\n",
    " 'max_features': 'auto',\n",
    " 'n_estimators': 50,\n",
    " 'oob_score': True,\n",
    " 'random_state': 42}\n",
    "pprint(best_params)\n",
    "print(0.8687141522110355)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-exclusion",
   "metadata": {},
   "source": [
    "Now that we have found our best model, we can re-train it on the whole training set, and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "arranged-impact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 50,\n",
       " 'oob_score': True,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fantastic-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653690186536902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(criterion='gini', max_depth=50, max_features='auto', n_estimators=50, random_state=42)\n",
    "\n",
    "x_train = column_transformer.fit_transform(x_train)\n",
    "x_train, y_train = SMOTENC(categorical_features=categorical_indices).fit_resample(x_train, y_train)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "x_test = column_transformer.transform(x_test)\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "administrative-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864963503649635"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "coastal-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-money",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
